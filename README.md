# S3 CLI Container - Nettoyage automatique

## Description

Ce projet fournit un conteneur Docker permettant de surveiller et nettoyer automatiquement les fichiers anciens dans des buckets S3 compatibles (AWS S3, Wasabi, MinIO, etc.). Le conteneur liste les fichiers, affiche leur √¢ge avec des codes couleur et peut supprimer automatiquement les fichiers de plus de X jours (configurable).

## Fonctionnalit√©s

- üßπ **Nettoyage automatique** : Suppression des fichiers de plus de X jours (configurable)
- üëÄ **Mode surveillance** : Affichage color√© de l'√¢ge des fichiers sans suppression
- üìä **Reporting d√©taill√©** : Codes couleur pour visualiser l'√¢ge des fichiers
- üîÑ **Ex√©cution flexible** : Mode continu (24h) ou unique (`RUN_ONCE`)
- üéØ **Multi-buckets** : Support de plusieurs buckets/dossiers simultan√©ment
- üåê **Compatibilit√© S3** : Fonctionne avec AWS S3, Wasabi, MinIO et autres services compatibles

## Configuration

### Variables d'environnement

#### Configuration AWS/S3 (obligatoire)
- `AWS_ACCESS_KEY_ID` : Cl√© d'acc√®s AWS/S3
- `AWS_SECRET_ACCESS_KEY` : Cl√© secr√®te AWS/S3  
- `AWS_DEFAULT_REGION` : R√©gion AWS (ex: eu-west-2)
- `ENDPOINT_URL` : URL du service S3 (pour services non-AWS comme Wasabi)

#### Configuration du nettoyage
- `BUCKET_NAME` : Liste des buckets/dossiers s√©par√©s par `|` (pipe)
- `MODE` : Mode d'op√©ration
  - Non d√©fini ou comment√© : **Mode surveillance** (affichage uniquement)
  - `clean` : **Mode nettoyage** (suppression effective des fichiers)
- `FILE_AGE` : √Çge limite en jours pour la suppression (d√©faut: 90, d√©fini automatiquement)
- `RUN_ONCE` : Si "true", ex√©cute une seule fois puis s'arr√™te (d√©faut: false)
- `SLEEP_TIME` : Intervalle en secondes entre les ex√©cutions (d√©faut: 86400 = 24h, d√©fini automatiquement)

### Exemple de configuration

```bash
# Configuration S3
AWS_ACCESS_KEY_ID=votre_access_key
AWS_SECRET_ACCESS_KEY=votre_secret_key
AWS_DEFAULT_REGION=eu-west-2
ENDPOINT_URL=https://s3.eu-west-2.wasabisys.com/

# Buckets √† surveiller (s√©par√©s par |)
BUCKET_NAME="mon-bucket|mon-bucket/dossier1|mon-bucket/dossier2"

# Mode de fonctionnement
#MODE=clean  # D√©commentez pour activer le nettoyage

# Configuration avanc√©e
FILE_AGE=90        # √Çge limite en jours
RUN_ONCE=true      # Ex√©cution unique puis arr√™t
SLEEP_TIME=86400   # Intervalle entre ex√©cutions (24h)
```

## Modes de fonctionnement

### Mode surveillance (d√©faut)
- ‚úÖ Liste tous les fichiers des buckets configur√©s
- üìä Affiche l'√¢ge de chaque fichier avec codes couleur
- ‚ö†Ô∏è **Aucune suppression** - mode s√©curis√© pour v√©rification

### Mode nettoyage
- üßπ Supprime automatiquement les fichiers de plus de `FILE_AGE` jours
- üìù Affiche les suppressions effectu√©es
- ‚ö†Ô∏è **Suppression d√©finitive** - utilisez avec pr√©caution

## Codes couleur

Le script utilise des codes couleur pour faciliter la lecture :

- üü¢ **Vert** : Nom des fichiers
- üü° **Jaune** : Fichiers r√©cents (< `FILE_AGE` jours)
- üü£ **Magenta** : Fichiers anciens (> `FILE_AGE` jours, candidats √† la suppression)
- üîµ **Bleu** : Nom des buckets en cours de traitement
- üî¥ **Rouge** : Actions de suppression (mode clean uniquement)

## Utilisation

### 1. Configuration

Modifiez le fichier `env` avec vos param√®tres :

```bash
AWS_ACCESS_KEY_ID=votre_access_key
AWS_SECRET_ACCESS_KEY=votre_secret_key
AWS_DEFAULT_REGION=eu-west-2
ENDPOINT_URL=https://s3.eu-west-2.wasabisys.com/
BUCKET_NAME="bucket1|bucket2/dossier|bucket3"
FILE_AGE=90
SLEEP_TIME=86400
RUN_ONCE=true
```

### 3. Ex√©cution

#### Mode surveillance (recommand√© pour d√©buter)
```bash
docker run --rm \
  --env-file env \
  s3cli:latest
```

#### Mode nettoyage (suppression effective)
```bash
docker run --rm \
  --env-file env \
  -e MODE=clean \
  s3cli:latest
```

#### Ex√©cution unique (recommand√© pour tests)
```bash
docker run --rm \
  --env-file env \
  -e RUN_ONCE=true \
  s3cli:latest
```

#### Ex√©cution en arri√®re-plan
```bash
docker run -d \
  --name s3cli-cleaner \
  --env-file env \
  -e MODE=clean \
  s3cli:latest
```

### 4. Exemple avec docker-compose

```yaml
services:
  s3cli-cleaner:
    build: .
    container_name: s3cli-cleaner
    env_file:
      - env
    environment:
      - MODE=clean        # Supprimez cette ligne pour le mode surveillance
      - FILE_AGE=90       # Optionnel, d√©faut: 90 jours
      - SLEEP_TIME=86400  # Intervalle entre ex√©cutions (24h par d√©faut)
      # - RUN_ONCE=true   # D√©commentez pour ex√©cution unique
    restart: unless-stopped
```

## Fonctionnement d√©taill√©

### Cycle d'ex√©cution

1. **Initialisation** : D√©finition des valeurs par d√©faut (`FILE_AGE=90`, `SLEEP_TIME=86400`)
2. **Scan des buckets** : Le container parcourt chaque bucket/dossier configur√©
3. **Analyse des fichiers** : Pour chaque fichier, calcule l'√¢ge en jours
4. **Affichage color√©** : Pr√©sente les r√©sultats avec codes couleur
5. **Action conditionnelle** : 
   - Mode surveillance : Affichage uniquement
   - Mode clean : Suppression des fichiers > `FILE_AGE` jours
6. **Pause** : 
   - `RUN_ONCE=true` : Arr√™t apr√®s une ex√©cution
   - Sinon : Attente de `SLEEP_TIME` secondes avant le prochain cycle

### Format des dates

Le script analyse les fichiers avec des dates au format `YYYY-MM-DD` dans leur nom ou m√©tadonn√©es S3.

### Crit√®res de suppression

- ‚è±Ô∏è **√Çge** : Plus de X jours (configurable via `FILE_AGE`)
- üìÅ **Scope** : Tous les buckets/dossiers configur√©s
- üîÑ **Fr√©quence** : V√©rification toutes les 24h (ou unique si `RUN_ONCE=true`)

## Exemples de sortie

### Mode surveillance
```
Configuration: FILE_AGE=90 jours, SLEEP_TIME=86400 secondes
--- Running Cleaning at Fri Oct 25 10:30:00 UTC 2025 ---
--- Parcours de backup ---
backup-2025-07-15.tgz : 102 jours
backup-2025-10-20.tgz : 5 jours
--- Parcours de backup/Mysql_Backup ---
mysql-dump-2025-06-01.sql.gz : 146 jours
--- RUN_ONCE is true, exiting after one run ---
```

### Mode nettoyage
```
Configuration: FILE_AGE=90 jours, SLEEP_TIME=86400 secondes
--- Running Cleaning at Fri Oct 25 10:30:00 UTC 2025 ---
--- Parcours de backup ---
backup-2025-07-15.tgz : 102 jours
Suppression de backup-2025-07-15.tgz dans backup
backup-2025-10-20.tgz : 5 jours
--- Sleeping 24h ---
```

## S√©curit√© et bonnes pratiques

### Recommandations de s√©curit√©
- üîê **Test pr√©alable** : Utilisez toujours le mode surveillance avant le mode clean
- üìã **Backup des credentials** : Stockez les fichiers `.env` avec permissions 600
- üéØ **Buckets sp√©cifiques** : Limitez aux buckets de sauvegarde uniquement
- üìù **Logs de surveillance** : Conservez les logs pour audit

### Workflow recommand√©

1. **Phase de test** : Lancez en mode surveillance avec ex√©cution unique
   ```bash
   docker run --rm --env-file env -e RUN_ONCE=true s3cli:latest
   ```

2. **V√©rification** : Examinez la sortie et identifiez les fichiers qui seraient supprim√©s

3. **Test de nettoyage** : Testez le nettoyage sur un petit √©chantillon
   ```bash
   docker run --rm --env-file env -e MODE=clean -e RUN_ONCE=true s3cli:latest
   ```

4. **Activation du nettoyage continu** : Une fois valid√©, activez le mode clean permanent
   ```bash
   docker run -d --name s3cli --env-file env -e MODE=clean s3cli:latest
   ```

## D√©pannage

### Probl√®mes courants

#### "No credentials found"
- **Cause** : Variables AWS non d√©finies ou incorrectes
- **Solution** : V√©rifiez `AWS_ACCESS_KEY_ID` et `AWS_SECRET_ACCESS_KEY`

#### "Unable to locate service"
- **Cause** : Region ou endpoint incorrect
- **Solution** : V√©rifiez `AWS_DEFAULT_REGION` et `ENDPOINT_URL`

#### Aucun fichier list√©
- **Cause** : Bucket inexistant ou permissions insuffisantes
- **Solution** : V√©rifiez les noms de buckets et les permissions S3

### V√©rification des logs

```bash
# Conteneur en cours d'ex√©cution
docker logs s3cli-cleaner

# Suivi en temps r√©el
docker logs -f s3cli-cleaner
```

### Test de connectivit√©

```bash
# Test rapide de connexion S3
docker run --rm --env-file env s3cli:latest aws s3 ls --endpoint-url $ENDPOINT_URL

# Test avec un bucket sp√©cifique
docker run --rm --env-file env s3cli:latest aws s3 ls s3://votre-bucket --endpoint-url $ENDPOINT_URL
```

## Personnalisation

### Valeurs par d√©faut

Le script d√©finit automatiquement les valeurs par d√©faut suivantes si les variables ne sont pas sp√©cifi√©es :
- `FILE_AGE=90` (90 jours)
- `SLEEP_TIME=86400` (24 heures en secondes)

Ces valeurs sont affich√©es au d√©marrage du conteneur pour confirmation.

### Modification du seuil d'√¢ge

Pour changer le seuil de jours, utilisez la variable d'environnement :
```bash
FILE_AGE=30  # Fichiers de plus de 30 jours
```

Ou directement dans la commande Docker :
```bash
docker run --rm --env-file env -e FILE_AGE=30 s3cli:latest
```

### Modification de la fr√©quence

Pour contr√¥ler la fr√©quence d'ex√©cution :

#### Ex√©cution unique
```bash
RUN_ONCE=true  # Ex√©cute une seule fois puis s'arr√™te
```

#### Modification de l'intervalle continu
Utilisez la variable d'environnement `SLEEP_TIME` (en secondes) :
```bash
SLEEP_TIME=3600  # 1 heure entre chaque ex√©cution
```

Exemples d'intervalles :
- `SLEEP_TIME=3600`  : 1 heure
- `SLEEP_TIME=21600` : 6 heures  
- `SLEEP_TIME=43200` : 12 heures
- `SLEEP_TIME=86400` : 24 heures (d√©faut)